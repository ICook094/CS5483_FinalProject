{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "006a14ad",
   "metadata": {},
   "source": [
    "# Setup \n",
    "Python Version: 3.13.2\n",
    "\n",
    "Possible pip installs needed: networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7620e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import networkx as nx\n",
    "import re\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c9dcda",
   "metadata": {},
   "source": [
    "## Load Data From File into Graph \n",
    "Assigned: Isabell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb41f02",
   "metadata": {},
   "source": [
    "#### Data format:\n",
    "\n",
    "\n",
    "Id:   15 \\\n",
    "ASIN: 1559362022\\\n",
    "title: Wake Up and Smell the Coffee\\\n",
    "  &emsp;group: Book\\\n",
    "  &emsp;salesrank: 518927\\\n",
    "  &emsp;similar: 5  1559360968  1559361247  1559360828  1559361018  0743214552\\\n",
    "  &emsp;categories: 3\\\n",
    "   &emsp;|Books[283155]|Subjects[1000]|Literature & Fiction[17]|Drama[2159]|United States[2160]\\\n",
    "   &emsp;|Books[283155]|Subjects[1000]|Arts & Photography[1]|Performing Arts[521000]|Theater[2154]|General[2218]\\\n",
    "   &emsp;|Books[283155]|Subjects[1000]|Literature & Fiction[17]|Authors, A-Z[70021]|( B )[70023]|Bogosian, Eric[70116]\\\n",
    "  &emsp;reviews: total: 8  downloaded: 8  avg rating: 4\\\n",
    "    &emsp;2002-5-13  cutomer: A2IGOA66Y6O8TQ  rating: 5  votes:   3  helpful:   2\\\n",
    "    &emsp;2002-6-17  cutomer: A2OIN4AUH84KNE  rating: 5  votes:   2  helpful:   1\\\n",
    "    &emsp;2003-1-2  cutomer: A2HN382JNT1CIU  rating: 1  votes:   6  helpful:   1\\\n",
    "    &emsp;2003-6-7  cutomer: A2FDJ79LDU4O18  rating: 4  votes:   1  helpful:   1\\\n",
    "    &emsp;2003-6-27  cutomer: A39QMV9ZKRJXO5  rating: 4  votes:   1  helpful:   1\\\n",
    "    &emsp;2004-2-17  cutomer:  AUUVMSTQ1TXDI  rating: 1  votes:   2  helpful:   0\\\n",
    "    &emsp;2004-2-24  cutomer: A2C5K0QTLL9UAT  rating: 5  votes:   2  helpful:   2\\\n",
    "    &emsp;2004-10-13  cutomer:  A5XYF0Z3UH4HB  rating: 5  votes:   1  helpful:   1\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a11116",
   "metadata": {},
   "source": [
    "### Load Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b946a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "    parameters:\n",
    "        path: path to amazon-meta.txt.gz file that should be stored locally. can be downloaded from https://snap.stanford.edu/data/amazon-meta.html\n",
    "\n",
    "    Note: Uses ASIN as node ids\n",
    "'''\n",
    "def load_amazon_undirected(path):\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    # Use regex to see if line of file is related :\n",
    "    # ASIN (Amazon Standard Identification Number)\n",
    "    asin_pattern = re.compile(r'^ASIN:\\s+(.+)$')\n",
    "    # similar (ASINs of co-purchased products)\n",
    "    similar_pattern = re.compile(r'^similar:\\s+(\\d+)\\s+(.+)$')\n",
    "    \n",
    "    # Keep track of current node\n",
    "    current_asin = None\n",
    "\n",
    "    # Open .txt.gz file as .txt\n",
    "    with gzip.open(path, 'rt', encoding='latin-1') as f:\n",
    "        # loop through each line\n",
    "        for line in f:\n",
    "            # Remove white space around characters\n",
    "            line = line.strip()\n",
    "\n",
    "            # Check if line contains a new node id (aka see if line contains ASIN regex)\n",
    "            asin_match = asin_pattern.match(line)\n",
    "            if asin_match:\n",
    "                # Update current node's ID\n",
    "                current_asin = asin_match.group(1)\n",
    "                # Create new node\n",
    "                G.add_node(current_asin)\n",
    "                continue\n",
    "\n",
    "            # Check if line contains node's co-purchases (aka see if line contains similar regex)\n",
    "            sim_match = similar_pattern.match(line)\n",
    "            if sim_match and current_asin is not None:\n",
    "                # Grab the list of similars (aka group 2)\n",
    "                similars_str = sim_match.group(2)\n",
    "                # Split string into a list so each co-purchase's ASIN is alone\n",
    "                similars = similars_str.split()\n",
    "                # Add each \n",
    "                for s in similars:\n",
    "                    if s != 'null':\n",
    "                        # Add co-purchase node (networkx does handle duplicates)\n",
    "                        G.add_node(s)\n",
    "                        # Create undirected edge between current node and co-purchase node\n",
    "                        G.add_edge(current_asin, s)\n",
    "    return G\n",
    "\n",
    "path = './amazon-meta.txt.gz'\n",
    "G = load_amazon_undirected(path)\n",
    "\n",
    "\n",
    "def preprocess_largest_component(G):\n",
    "    # Create Copy of G for preprocessing\n",
    "    G_preprocessed = copy.deepcopy(G)\n",
    "    \n",
    "    # Duplicates are handled by networkx itself\n",
    "    \n",
    "    # Remove self loops\n",
    "    self_loops = list(nx.selfloop_edges(G_preprocessed))\n",
    "    G_preprocessed.remove_edges_from(self_loops)\n",
    "    \n",
    "    # Remove isolated nodes\n",
    "    isolates = list(nx.isolates(G_preprocessed))\n",
    "    G_preprocessed.remove_nodes_from(isolates)\n",
    "    \n",
    "    # Find largest connected component\n",
    "    # Find all components\n",
    "    comps = list(nx.connected_components(G_preprocessed))\n",
    "    # Grab largest component\n",
    "    largest_comp_nodes = max(comps, key=len)\n",
    "    # Create subgraph of largest component and make sure its undirected\n",
    "    G_Largest = G_preprocessed.subgraph(largest_comp_nodes).copy().to_undirected()\n",
    "    \n",
    "    return G_preprocessed, G_Largest\n",
    "    \n",
    "\n",
    "# A preprocessed Graph of G, and grab its largest component\n",
    "G_processed, G_largest =  preprocess_largest_component(G)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff05d175",
   "metadata": {},
   "source": [
    "### Graph Details:\n",
    "\n",
    "*** TODO *** by Isabell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275a0a64",
   "metadata": {},
   "source": [
    "## Centralities\n",
    "Assigned: Isabell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08193fce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f0e23ce",
   "metadata": {},
   "source": [
    "## Community Detection\n",
    "Assigned: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0912dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea671811",
   "metadata": {},
   "source": [
    "## Link Prediction\n",
    "Assigned: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba44de7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
